{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ôn tập kiến thức thi cuối kì\n",
    "1. Học tăng cường.\n",
    "2. Mô hình Markov, Markov ẩn.\n",
    "3. Clustering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Học tăng cường\n",
    "- Decision maker: agent được đặt trong một môi trường (environment)\n",
    "- Học tăng cường là các thức 1 agent trong một môi trường nên chọn thực hiện các hành động nào để cực đại hóa điểm thưởng (reward) nào đó về lâu dài.\n",
    "- policy là một ánh xạ từ tập trạng thái cửa môi trường tới tập các hành động.\n",
    "- Finite-horizon\n",
    "- Infinite-horizon\n",
    "- Bellman's quation\n",
    "- Policy:\n",
    "  + Lưu trữ và cập nhật các chiến lược thay vì làm điều này gián tiếp qua các giá trị.\n",
    "  + Ý tưởng là để bắt đầu với 1 chiến lược và cải thiện liên tục cho đến khi không còn thay đổi.\n",
    "- Q learning: Hàm ước lượng giá trị tích lũy lớn nhất khi thực hiện hành động a tại trạng thái s. Xét môi trường xác định.\n",
    "- Sử dụng xác suất (e-greedy):\n",
    "  + Với xác suất nhỏ hơn e, chịn hành dộng một các ngẫu nhiên giữa các hành dộng có thể, explore (khám phá).\n",
    "  + Ngược lại với xác suất lơn hơn e, chọn hành động tốt nhất exploit (khai thác)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô hình Markov, Markov ẩn.\n",
    "- Một số khái niệm:\n",
    "  + Ngẫu nhiên: không biết chắc kết quả nào sẽ xảy ra, nhưng biết được các kết quả sẽ xảy ra.\n",
    "  + Không gian mẫu: tập hợp các kết quả có thể xảy ra trong thí nghiệm ngẫu nhiên, kí hiều S.\n",
    "  + Biến cố: tập con của không gian mẫu, ký hiệu E.\n",
    "  + Biến cố sơ đẳng chỉ chưa 1 phần tử của S.\n",
    "  + Xác suất: số lần xuất hiện của 1 biến cố E nào đó trên tổng số lần trong 1 thí nghiệm ngẫu nhiên.\n",
    "- Xác suất có điều kiện:\n",
    "- Thuộc tính Markov:\n",
    "  + Một dãy các trạng thái ngẫu nhiên được gọi là thuộc tính Markov nếu như xác suất chuyển sang trạng thái tiếp theo chỉ phụ thuộc vào trạng thái hiện tại.\n",
    "  + Dãy chuyển trạng thái quan sát được -> Xích Markov/ Mô hình Markov.\n",
    "  + Dãy chuyển trạng thái không quán sát được -> Mô hình Markov ẩn.\n",
    "- Markov bậc 1:\n",
    "  + 1 mắt xích phụ thuộc vào mắt xích liền kề.\n",
    "- Markov bậc 2:\n",
    "  + 1 mắt xích phụ thuộc vào 2 mắt xích liền kề.\n",
    "- Hạn chế của Markov: một trong những thông số đặc trưng của mô hình Markov là các trạng thái state. Tùy thuộc vào việc xây dựng mô hình Markov có những hạn chế trong nhiều ứng dụng như giá trị chuyển trạng thái là những giá trị áp đạt sẵn, không thay đổi trong khi đối tượng quan sát luôn thay đổi theo thời gian. Để khắc phục tình trạng này chúng ta sử dụng mô hình hidden Markov.\n",
    "\n",
    "# Hidden Markov Model: Có thêm 1 dãy Observation (quan sát quá trình chuyển trạng thái).\n",
    "- Thuật giải:\n",
    "  + Forward procedure:\n",
    "  + Backward procedure:\n",
    "# Thuật giải Baum-Welch: \n",
    "- Thuật giải có thể chỉ cho lời giải chỉ đạt được cực trị địa phương -> cho thuật giải chạy 1 số lần nào đó mặc dù điều kiện hội tụ. Vì các tham số của mô hình là các giá trị xác suất nên các giá trị khởi tạo ban đầu cho tham số của mô hình dương và có tổng = 1. Dữ liệu huấn luyện không đủ, chuỗi huấn luyện phải đủ dài. Scaling: giá trị sẽ tiến về 0 rất nhanh.\n",
    "\n",
    "# Thuật giải Viterbi:\n",
    "- Tìm chuỗi trạng thái ăn có xác suất lớn nhất nhưng chi phí nhở nhất."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering:\n",
    "- Định nghĩa: là quá trình phân chia 1 tập dữ liệu ban đầu thành các cụm thỏa mãn:\n",
    "  + Các đối tượng trong 1 cụm tương tự nhau.\n",
    "  + Các đối tượng khác cụm thì không tương tự nhau.\n",
    "- Giải quyết vấn đề tìm kiếm, phát hiện các cụm, các mẫu dữ liệu trong 1 tập dữ liệu ban đầu không có nhãn.\n",
    "- Các phương pháp phân cụm điển hình:\n",
    "  + Phân cụm phân hoạch.\n",
    "  + Phân cụm phân cấp.\n",
    "  + Phân cụm dựa trên lý thuyết đồ thị.\n",
    "  + Phân cụm theo hàm tối ưu.\n",
    "  + Phân cụm dựa trên mật độ.\n",
    "  + Phân cụm dựa trên lưới.\n",
    "  + Phân cụm dựa trên mô hình.\n",
    "  + Phân cụm có ràng buộc.\n",
    "\n",
    "# Tổng quan về HAC:\n",
    "- Là một thuật toán phân cụm không giám sát (không cần biết số cụm cần phân vào) nhưng phải cung cấp điều kiện dừng. Sau khi phân cụm ta được lược đồ (dendro).\n",
    "- Có 2 phương pháp:\n",
    "  + Agglomerative: Đi từ dãy các phân tử và ở mỗi bước gom nhóm các cặp phân vùng (có thể là 1 phần tử hay 1 nhóm có nhiều phần tử đã gom nhóm vào) có khoảng các giữa 2 phần tử là gần nhau nhất. Cứ như thế cho đến khi chỉ còn lại 1 nhóm.\n",
    "  + Divisive: Các này đi ngược với cách làm trên.\n",
    "- Single link: khoảng cách nhỏ nhất giữa 2 đối tượng thuộc về 2 cụm.\n",
    "- COmplete link: Khoảng các xa nhất giữa hai đối tượng thuộc về 2 cụm.\n",
    "- WPGMA: Khoảng các trung bình giữa các đối tượng trong 2 cụm đó.\n",
    "- Thuật toán phân cụm và phân rã: quá trình ngược lại với thuật toán (Agglomerative). Ban đầu chúng ta xem tất cả cáct đối tượng thuộc cùng 1 cụm, sau đó tiến hành phân thành 2 cụm con. Quá trình này được thực hiện cho đến khi mỗi cụm chỉ còn 1 đối tượng.\n",
    "- Thuật toán phân cụm (GAS): \n",
    "  + Dựa trên lý thuyất mà trận.\n",
    "  + Dựa trên lý thuyết đồ thị:\n",
    "    - Node degree: là số nguyên k lớn nhất sao cho mỗi node có ít nhất k đường đi.\n",
    "    - Node connectivity: là số nguyên k lớn nhất sao cho 2 node bất kỳ có ít nhất k đường đi giữa chúng mà không có node nào chung.\n",
    "    - Edge connectivity: là số nguyên k lớn nhất sao cho 2 cạnh bất kỳ có ít nhất k đường đi giữa chúng mà không có canh nào chung.\n",
    "- Lựa chọn phân cụm như thế nào?\n",
    "Không nhất phải tọa được n cụm, việv phân cụm kết thúc khi sự phụ hợp nhất của dữ liệu đạt đượcphuf hợp với tiêu chí.\n",
    "=> Hầu hết các hàm clustering dựa trên sự tối ưu hóa của hàm cconst function"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
