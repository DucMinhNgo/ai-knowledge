{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23/2/2023: Thi giữ kì\n",
    "\n",
    "6h15 - 7h30: học bình thường\n",
    "- Học tăng cường\n",
    "7h30 - 8h15: Thi trắc nghiệm:\n",
    "Nội dung (mở):\n",
    "- Giới thiệu máy học\n",
    "- Cây quyết định\n",
    "- Mạng neural network\n",
    "- Thuật giải di truyền\n",
    "- Học theo nhóm kết hợp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting and Adasboost \n",
    "- Dựa trên nguyên lý số đông\n",
    "- Dựa trên nhóm chuyên gia tạo ra kết quả đối sánh\n",
    "- Phải có sự độc lập giữa các đối tượng\n",
    "- Áp dụng tổ hợp trong máy tính\n",
    "  + A strong learner:\n",
    "  + A weak learner:\n",
    "\n",
    "- Học tổ hợp là tìm cách hết hợp tuyến tính những bộ phân lớp yếu để đạt được bộ phân lớp mạnh\n",
    "  + Sử dụng khi tìm không ra bộ phân lớp mạnh\n",
    "  + Có tài nguyên các phương pháp để tạo nên một lớp phân lớp yếu.\n",
    "  + Kết hợp nhue thế nào để tạo thành một phân lớp mạnh\n",
    "  + Phân lớp yếu lớn hơn 0.5 một chút (nếu dùng mô hình mạnh thì pens sẽ tiến về 0)\n",
    "\n",
    "- Phân tích bias và variance:\n",
    "  - Phân tích lỗi dựa trên 3 đặc điểm: Intrisic (bản chất), variance: độ chênh lệch giữa giá trị thực và giá trị dự đoán, Bias: thông số điều chỉnh làm thay đổi giá trị variance.\n",
    "\n",
    "- ý tưởng:\n",
    "  - chia ngang, trộn một phần tập lỗi của thuật toán này với thuật toán khác tập lỗi.\n",
    "\n",
    "- Nguyên tắc:\n",
    "  - Chọn phân lớp đơn giản hơn, nếu 2 phân lớp có cùng lỗi tổng hợp. Đơn giản hơn tức là có ít tham số hơn. \n",
    "\n",
    "- Để chống th overfit:\n",
    "  + cross validation (bản chất từ nguyên tắc bagging).\n",
    "\n",
    "- Nguyên tắc kết hợp thông dung:\n",
    "  + Trung bình.\n",
    "  + kết hợp các trọng số theo tỉ lệ. Cơ chế tính ra trọng số.\n",
    "\n",
    "# Adaboost:\n",
    "- Định nghĩa một lớp làm phân lớp yếu (tập hợp các hàm phân lớp yếu).\n",
    "- Mỗi điểm dữ liệu thì có một giá trị trọng số => trọng số alpha. Khởi tạo ban đầu trọng số của các điểm dữ liệu đều nhau. Điểm dữ liệu có trọng số lớn là điểm sai. Phân lớp có độ chính xác thấp đi sửa lỗi của nhứng lớp có độ chính xác cao. (odd) lấy xác suất đúng chia xác suất sai.\n",
    "- Xem lại đồ thị hàm lg, e^(x)\n",
    "- Chia 1 số rất lớn để đưa dữ liệu về 0->1.\n",
    "- Trọng số tăng lên khi sai giảm khi đúng.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
