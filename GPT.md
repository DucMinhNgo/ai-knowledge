GPT (generative Pre-training transformer) là một phần mềm tạo văn bản AI phát triển trên OpenAI của Elon Musk.
- Dựa trên mô hình hai mạng thần kinh tự cạnh tranh và hoàn thiện lẫn nhau. CHỉ dựa trên dư liệu đầu vào hạn hẹp, GPT có thể tạo ra những đoạn văn bản hoàn chỉnh.

GPT2 mức độ hoàn chỉnh cao hơn. Trước đó Elon musk từ chối công bố GPT2 bởi ông lo ngại nó được dùng để tạo tin đăng tải giả lên các mạng xã hội.

GPT3 có khả năng xử lý 175 tỷ tham số so với 1,5 tỷ của GPT2.
Khi bạn đưa vào GPT3 bất cứ tham số nào bạn cũng sẽ nhận về một văn bản hoàn thiện, phù hợp nhất với những gì bạn đưa ra
GPT-3 cần sức mạnh tính toán vài nghìn petaflop/s trong khi GPT2 chỉ cần vài chục petaflot/s